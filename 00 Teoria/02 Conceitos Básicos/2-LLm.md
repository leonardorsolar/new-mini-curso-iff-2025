# Pergunta 1: LLM

**FaÃ§a a pergunta ao chatgpt:**

1- O que Ã© LLM e quais sao as principais existentes no mercado?

---

# Pergunta 2: DiferenÃ§a entre **usar uma LLM diretamente** e **usar uma LLM dentro de um agente**.

**FaÃ§a a pergunta ao chatgpt:**

1- Quando eu dou um input de uma tarefa para o llm Ã© uma coisa mas quando eu construo um agente com prompt e dou um input Ã© outra coisa. Me explique

---

# Pergunta 3: regras, comandos, tarefas, agentes e subagentes

**FaÃ§a a pergunta ao chatgpt:**

3- Tenho dÃºvida do que Ã© regras, comandos, tarefas, agentes e subagentes

---

# LLMs = Tecnologias / â€œCÃ©rebrosâ€

Modelos de linguagem treinados para entender e gerar texto:

GPT-4, GPT-4o â†’ da OpenAI
Gemini 1.5 Pro, Flash â†’ do Google
Claude 3 Opus, Sonnet, Haiku â†’ da Anthropic
Grok-1.5 â†’ da xAI
Qwen-Max, Qwen-Turbo â†’ da Alibaba

# ğŸ”¹ O que sÃ£o **tokens**

-   Um **token** Ã© uma **unidade de texto** que o modelo de IA usa para **entender e gerar linguagem**.
-   NÃ£o Ã© exatamente uma palavra, mas um pedaÃ§o dela.
-   Dependendo do idioma e da palavra, um token pode ser:

    -   Uma palavra inteira curta â†’ `cachorro` pode ser **1 token**.
    -   Uma parte de uma palavra â†’ `informÃ¡tica` pode virar **2 tokens**: `infor` + `mÃ¡tica`.
    -   AtÃ© mesmo espaÃ§os, pontuaÃ§Ã£o e quebras de linha contam como tokens.

---

# tokens

https://platform.openai.com/tokenizer

Todos os modelos tem limitaÃ§Ãµes na quantidade de tokens que conseguem aceitar como entrada, o GPT-5 tem limite de 400k tokens enquanto o Claude Opus 4 tem 200k tokens e o Google Gemini 2.5 Pro tem 1M de tokens em sua context window

## ğŸ”¹ Exemplos prÃ¡ticos

Frase:
ğŸ‘‰ `"Eu gosto de estudar IA."`

-   Em tokens poderia ser dividido assim:

    -   `Eu` â†’ 1 token
    -   `gosto` â†’ 1 token
    -   `de` â†’ 1 token
    -   `estudar` â†’ 1 token
    -   `IA` â†’ 1 token
    -   `.` â†’ 1 token

â¡ï¸ Total: **6 tokens**

---

## ğŸ”¹ Por que tokens importam?

1. **Limite de contexto**

    - Cada modelo de IA tem um limite mÃ¡ximo de tokens que consegue processar de uma vez (a â€œcontext windowâ€).
    - Exemplo: GPT-4 tem versÃµes de 8k, 32k ou mais tokens. Isso define **quanto de texto vocÃª pode colocar** no chat de uma vez.

2. **Custo (\$)**

    - Como no Cursor (e em APIs), o custo Ã© calculado por **nÃºmero de tokens processados**.
    - Se vocÃª manda um texto de 2.000 palavras, pode virar uns **2.500 a 3.000 tokens**.

3. **Performance**

    - Quanto mais tokens, mais demorado (e caro).
    - Por isso Ã© Ãºtil dar **contexto relevante**, em vez de jogar tudo.

---

## ğŸ”¹ ComparaÃ§Ã£o rÃ¡pida

-   **Tokens = combustÃ­vel**

    -   Quanto mais tokens, mais informaÃ§Ã£o a IA consegue ler ou gerar.

-   **Prompt longo = mais tokens gastos**
-   **Resposta longa = mais tokens gastos**

---

ğŸ‘‰ Em resumo: **tokens sÃ£o os pedaÃ§os de texto que a IA processa.**
Eles definem:

-   **O quanto vocÃª pode conversar sem a IA esquecer.**
-   **Quanto vai custar usar o modelo.**

---
